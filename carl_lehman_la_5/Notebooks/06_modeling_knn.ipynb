{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to my Logistic Regression notebook, in this notebook I will fit a k-nearest neighbor model on count vectorized data, TFIDF data, and count vectorized data with sentiment analysis in the attempts to create a model that can differentiate between the subreddits. If I am successful at doing so, this will provide as evidence that democrats and republicans have a preference for topics to discuss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction import stop_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading in my train, test splitted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = pd.read_csv('../Data/reddit.csv', index_col=0)\n",
    "X_train = pd.read_csv('../Data/X_train.csv', header = None, index_col=0)\n",
    "X_test = pd.read_csv('../Data/X_test.csv', header = None, index_col=0)\n",
    "y_train = pd.read_csv('../Data/y_train.csv', header = None, index_col=0)\n",
    "y_test = pd.read_csv('../Data/y_test.csv', header = None, index_col=0)\n",
    "X_train_sen = pd.read_csv('../Data/X_train_sen.csv', index_col=0)\n",
    "X_test_sen = pd.read_csv('../Data/X_test_sen.csv', index_col=0)\n",
    "y_train_sen = pd.read_csv('../Data/y_train_sen.csv', header = None, index_col=0)\n",
    "y_test_sen = pd.read_csv('../Data/y_test_sen.csv', header = None, index_col=0)\n",
    "reddit.fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a list of custom stop words that include numbers and some terms found in urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_stopwords = list(stop_words.ENGLISH_STOP_WORDS)\n",
    "custom_stopwords.extend(['10', '12', '13', '14', '15', '18', '25','200', '000','https', 'com', 'youtube', 'www'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN on TFIDF data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TFIDF stands for term frequency inverse document frequency, and it essentially gives a word a ratio for how much it appears in the document. I will tokenize my data using TFIDF, then I will run a k-nearest neighbors classifier model on said data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words=custom_stopwords)),\n",
    "    ('knn', KNeighborsClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After extensive grid searching, these are the best parameters I've found to maximize accuracy:\n",
    "\n",
    "tfidf_min_df: ignore words that aren't found in at least 1 post\n",
    "\n",
    "tfidf_max_df: ignore words that are found in over $65 \\%$ of the documents\n",
    "\n",
    "tfidf_norm: Regularize the data with an l1 norm\n",
    "\n",
    "knn_n_neighbors: 50 of the closet neighbors to a point get to vote on what that point's class is\n",
    "\n",
    "knn_n_weights: weight each point based on distance\n",
    "\n",
    "knn_n_metric: measure distance with the manhattan metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'tfidf__min_df': [1,3,5,7],\n",
    "    'tfidf__max_df': [.65,.70,.75,.85],\n",
    "    'tfidf__norm': ['l1','l2'],\n",
    "    'knn__n_neighbors': [40,50,60,70],\n",
    "    'knn__weights': ['uniform', 'distance'],\n",
    "    'knn__metric': ['minkowski', 'euclidean', 'manhattan']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSearchCV(pipe, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       " ...owski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'))]),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'tfidf__min_df': [1, 3, 5, 7], 'tfidf__max_df': [0.65, 0.7, 0.75, 0.85, 0.9], 'tfidf__norm': ['l1', 'l2'], 'knn__n_neighbors': [40, 50, 60, 70], 'knn__weights': ['uniform', 'distance'], 'knn__metric': ['minkowski', 'euclidean', 'manhattan']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.fit(X_train[1], y_train[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring my model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9887323943661972"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.score(X_train[1],y_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6028169014084507"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.score(X_test[1],y_test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'knn__metric': 'manhattan',\n",
       " 'knn__n_neighbors': 50,\n",
       " 'knn__weights': 'distance',\n",
       " 'tfidf__max_df': 0.65,\n",
       " 'tfidf__min_df': 1,\n",
       " 'tfidf__norm': 'l1'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My model did not score better than any of my logistic regression models and is more overfit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN on count vectorized data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'll tokenize my data by using counting the appearance of each tearm in each post. Then I'll fit a k-nearest neighbors model to said data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer(stop_words=custom_stopwords)),\n",
    "    ('knn', KNeighborsClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After extensive grid searching I found the best parameters to optimize accuracy would be:\n",
    "\n",
    "cvec_min_df: Ignore words that don't appear in at least 3 documents\n",
    "\n",
    "cvec_max_df: Ignore words that appear in over $85 \\%$ of the documents\n",
    "\n",
    "cvec_ngram_range: (1,2) Consider each word individually and pairs of words\n",
    "\n",
    "knn_n_neighbors: 40 of the closest neighbors to a point get to vote on that point's class\n",
    "\n",
    "knn_weights: each point has a uniform weight\n",
    "\n",
    "knn_metric: distance is measured using the minkowski metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'cvec__min_df': [1,3,5],\n",
    "    'cvec__max_df': [.85,.9,.95,1.0],\n",
    "    'cvec__ngram_range': [(1,1),(1,2)],\n",
    "    'knn__n_neighbors': [30,40,50],\n",
    "    'knn__weights': ['uniform', 'distance'],\n",
    "    'knn__metric': ['minkowski', 'euclidean', 'manhattan']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSearchCV(pipe, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('cvec', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None,\n",
       "        stop_words=['ourselves...owski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'))]),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'cvec__min_df': [1, 3, 5], 'cvec__max_df': [0.85, 0.9, 0.95, 1.0], 'cvec__ngram_range': [(1, 1), (1, 2)], 'knn__n_neighbors': [30, 40, 50], 'knn__weights': ['uniform', 'distance'], 'knn__metric': ['minkowski', 'euclidean', 'manhattan']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.fit(X_train[1], y_train[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring my model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6046948356807512"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.score(X_train[1],y_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5633802816901409"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.score(X_test[1],y_test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 0.85,\n",
       " 'cvec__min_df': 3,\n",
       " 'cvec__ngram_range': (1, 2),\n",
       " 'knn__metric': 'minkowski',\n",
       " 'knn__n_neighbors': 40,\n",
       " 'knn__weights': 'uniform'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My model scored worse than my intial one with an accuracy of $56.3 \\%$. However, it is not overfit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN on count vectorized data with sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if adding features for sentiment analysis will improve my models accuracy in classifying the subreddits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer(stop_words=custom_stopwords)),\n",
    "    ('knn', KNeighborsClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After extensive grid searching, I found that the best parameters for my model to be as follows:\n",
    "\n",
    "n_neighbors: 30 neighbors get to vote on each points class\n",
    "\n",
    "weights: each point is weighted by distance\n",
    "\n",
    "metric: distance is measured using the minkowski metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'n_neighbors': [30,40,50],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['minkowski', 'euclidean', 'manhattan']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSearchCV(KNeighborsClassifier(), params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'n_neighbors': [30, 40, 50], 'weights': ['uniform', 'distance'], 'metric': ['minkowski', 'euclidean', 'manhattan']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.fit(X_train_sen,y_train_sen[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9624413145539906"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.score(X_train_sen,y_train_sen[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5492957746478874"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.score(X_test_sen,y_test_sen[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metric': 'minkowski', 'n_neighbors': 30, 'weights': 'distance'}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My model scored a record low of $54.9 \\%$, which is only about $5 \\%$ better than a coin flip. This is surprising given that we included sentiment analysis. My model is also severely overfit in this case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could not create a k-nearest neighbor model that scored better than $60 \\%$ on our accuracy metric. Since our model had a difficiult time differentiating between the two subreddit's posts, this is further evidence that democrats and republicans discuss similar topics. In my next modeling notebook, I will try to fit a random forest model to the same train, test splitted data. Random forest models are an ensemble method, meaning that several models are fit and used to determine classes. Since several models are greater than one model, random forest will assumedly perform better on our seemingly indiscernible data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
